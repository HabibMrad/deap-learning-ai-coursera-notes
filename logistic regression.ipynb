{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic Regression for Classification of Digits\n",
    "\n",
    "I get pretty good results on 0 vs 1, implying that telling the difference between a \"0\" and a \"1\" is not a hard problem anymore. Also pretty epic results on predicting 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load \"zeros\" and \"ones\" training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "digits = load_digits(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=9, figsize=(20,10))\n",
    "plt.gray()\n",
    "\n",
    "for i in range(9):\n",
    "    axes[i].imshow(digits.images[i])\n",
    "    axes[i].set_title(digits.target[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(digits.images, digits.target)\n",
    "\n",
    "train_x, test_x = [x.reshape(x.shape[0], -1).T / 16 for x in [train_x, test_x]]\n",
    "train_y, test_y = [y.reshape(1, y.shape[0]) for y in [train_y, test_y]]\n",
    "\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whip up a quick gradient descent loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, step_size, epochs):\n",
    "    w, b = np.random.randn(X.shape[0], 1), 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        yhat = 1 / (1 + np.exp( - (np.dot(w.T, X) + b)))\n",
    "\n",
    "        if (i % (epochs/10) == 0):  print(\"Cost at iteration {}: {}\".format(i, -np.mean(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))))\n",
    "\n",
    "        w = w - step_size * (1 / w.shape[0]) * np.dot(X, (yhat - y).T) \n",
    "        b = b - step_size * np.mean(yhat - y)\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how accurate we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w, b = gradient_descent(train_x, train_y, 0.001, 100000)\n",
    "        \n",
    "predict = lambda X, w, b: np.array((1 / (1 + np.exp(-1 * (np.dot(w.T, X) + b)))) > 0.5, dtype=int)\n",
    "accuracy = lambda y, yhat: np.mean(y == yhat) * 100\n",
    "\n",
    "print(\"Accuracy on train set: {}%\".format(accuracy(train_y, predict(train_x,w,b))))\n",
    "print(\"Accuracy on test set: {}%\".format(accuracy(test_y, predict(test_x,w,b))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Let's try predicting more than binary and try predict 0 through 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "digits10 = load_digits(10)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(20,10))\n",
    "plt.gray()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(digits10.images[i])\n",
    "    axes[i].set_title(digits10.target[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# need to wrangle the data to vectors\n",
    "scale = digits10.images.max()\n",
    "\n",
    "# a matrix with each row representing the image, and \"normalized\" by dividing through max\n",
    "X = digits10.images.reshape(digits10.images.shape[0], -1) / scale\n",
    "\n",
    "# one hot encode the output\n",
    "y = np.zeros((len(digits10.target), 10))\n",
    "y[np.arange(len(digits10.target)), digits10.target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for convenience, change X and y to be a matrix where each *column* represents the training input/output\n",
    "train_x, test_x, train_y, test_y = (np.array(set.T) for set in train_test_split(X, y))\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dimensions(X,y): \n",
    "    '''\n",
    "    c = the number of classifications possible for each given ouput\n",
    "    D = the number of features\n",
    "    m = number of training samples\n",
    "    '''\n",
    "    c = y.shape[0]\n",
    "    D, m = X.shape\n",
    "    return c, D, m\n",
    "\n",
    "c, D, m = dimensions(train_x, train_y)\n",
    "print(c,D,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$\\mathbf{z} = \\mathbf{w}^T\\mathbf{X} + \\mathbf{b}$\n",
    "\n",
    "$ \\mathbf{z} = \n",
    "\\\n",
    "\\begin{bmatrix} \\\n",
    "z_1^{(1)} & z_1^{(2)} & \\cdots & z_1^{(m)} \\\\\n",
    "z_2^{(1)} & z_2^{(2)} & \\cdots & z_2^{(m)} \\\\\n",
    "\\vdots & \\vdots &  \\ddots &  \\\\\n",
    "z_c^{(1)} & z_c^{(2)} &   & z_c^{(m)} \\\\\n",
    "\\end{bmatrix} \\\n",
    "= \\\n",
    "\\begin{bmatrix} \\\n",
    "w_{1,1} & w_{1,2} & \\cdots & w_{1,D} \\\\\n",
    "w_{2,1} & w_{2,2} & \\cdots & w_{2,D} \\\\\n",
    "\\vdots & \\vdots & \\ddots &  \\\\\n",
    "w_{c,1} & w_{c,2} &  & w_{c,D} \\\\\n",
    "\\end{bmatrix} \\\n",
    "\\\n",
    "\\begin{bmatrix} \\\n",
    "x_1^{(1)} & x_1^{(2)} & \\cdots & x_1^{(m)} \\\\\n",
    "x_2^{(1)} & x_2^{(2)} & \\cdots & x_2^{(m)} \\\\\n",
    "\\vdots & \\vdots &  \\ddots &  \\\\\n",
    "x_D^{(1)} & x_D^{(2)} &   & x_D^{(m)} \\\\\n",
    "\\end{bmatrix}\n",
    " + \\\n",
    "\\begin{bmatrix} \\\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "\\vdots\\\\\n",
    "b_c \\\\\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\mathbf{\\hat{y}} = ({1 + e^{-\\mathbf{z}}})^{-1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize our weights and biases to zero\n",
    "w = np.zeros((D,c))\n",
    "b = np.zeros((c,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "z = lambda w,X,b: np.dot(w.T, X) + b\n",
    "yHat = lambda z: 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$ \\mathcal{L}( \\mathbf{y}^{(i)}, \\mathbf{\\hat{y}}^{(i)}) = -(\\\n",
    "\\mathbf{y}^{(i)} \\cdot \\ln{\\mathbf{\\hat{y}}^{(i)}} + \\\n",
    "(1 - \\mathbf{y}^{(i)}) \\cdot \\ln{(1 - \\mathbf{\\hat{y}}^{(i)})})\n",
    "$\n",
    "\n",
    "$\n",
    "\\mathbf{J} = -\\frac{1}{m} \\sum_i^m \\mathcal{L}( \\mathbf{y}^{(i)}, \\mathbf{\\hat{y}}^{(i)})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "J = lambda y, yHat: -np.mean(y * np.log(yHat) + (1 - y) * np.log(1 - yHat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$ \\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$ \\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{\\hat{y}}} = \\\n",
    "\\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1 - \\mathbf{y}}{1 - \\mathbf{\\hat{y}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$ \\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} = \\mathbf{\\hat{y}}(1 - \\mathbf{\\hat{y}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$ \\frac{\\delta \\mathbf{\\hat{z}}}{\\delta \\mathbf{w}} = \\mathbf{X} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$ \\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} = \\\n",
    "\\Big[\\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1 - \\mathbf{y}}{1 - \\mathbf{\\hat{y}}}\\Big] \\dot \\\n",
    "\\mathbf{\\hat{y}}(1 - \\mathbf{\\hat{y}}) \\cdot \\mathbf{X} = \\\n",
    "(\\mathbf{\\hat{y}} - \\mathbf{y}) \\cdot \\mathbf{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dJdw = lambda X, y, yHat: np.dot(X, (yHat - y).T) / len(X)\n",
    "dJdb = lambda y, yHat: np.mean(yHat - y, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = yHat(z(w,train_x,b))\n",
    "assert(a.shape == train_y.shape)\n",
    "\n",
    "dw = dJdw(train_x, train_y, a)\n",
    "assert(dw.shape == w.shape)\n",
    "\n",
    "db = dJdb(train_y, a)\n",
    "assert(db.shape == b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "alpha = 0.001\n",
    "\n",
    "def descend(X, y, w, b):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        a = yHat(z(w,X,b))\n",
    "        \n",
    "        if (i % (epochs / 10) == 0): print(\"cost at iteration {}: {}\".format(i,J(y, a)))\n",
    "            \n",
    "        w = w - alpha * dJdw(X, y, a)\n",
    "        b = b - alpha * dJdb(y, a)\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c, D, m = dimensions(train_x, train_y)\n",
    "\n",
    "w = np.zeros((D,c))\n",
    "b = np.zeros((c,1))\n",
    "\n",
    "w, b = descend(train_x, train_y, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracy = lambda y, yhat: np.mean(y.argmax(axis=0) == yhat.argmax(axis=0)) * 100\n",
    "\n",
    "print(\"Accuracy on train set: {} %\".format(accuracy(train_y, yHat(z(w,train_x,b)))))\n",
    "print(\"Accuracy on test set: {}%\".format(accuracy(test_y, yHat(z(w,test_x,b)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for sample in range(20):\n",
    "    actual = test_y.argmax(axis=0)[sample]\n",
    "    prediction = yHat(z(w,test_x,b)).argmax(axis=0)[sample] \n",
    "    print(actual, prediction, actual == prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
