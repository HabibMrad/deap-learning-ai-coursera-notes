{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset['data']\n",
    "\n",
    "Y = np.zeros((len(dataset['target']), 3))\n",
    "Y[np.arange(len(dataset['target'])), dataset['target']] = 1\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 112), (4, 38), (3, 112), (3, 38)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = [np.array(M.T) for M in train_test_split(X, Y, random_state=1)]\n",
    "[m.shape for m in (train_x, test_x, train_y, test_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Shallow neural network, with one hidden layer and an output layer, using relu activation function for hidden layer and sigmoid activation for output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{z} = \\mathbf{w}\\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{a} = \\frac{1}{1 + e^{-\\mathbf{z}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.5],\n",
       "       [ 2.8],\n",
       "       [ 4.6],\n",
       "       [ 1.5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_x[:,:1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_y[:,:1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641, -0.52817175, -1.07296862],\n",
       "       [ 0.86540763, -2.3015387 ,  1.74481176, -0.7612069 ],\n",
       "       [ 0.3190391 , -0.24937038,  1.46210794, -2.06014071]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "w = np.random.randn(y.shape[0], x.shape[0])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros((y.shape[0], 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.80628391],\n",
       "       [ 6.065165  ],\n",
       "       [ 5.01100252]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.dot(w,x) + b\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{z} = \\\n",
    "\\mathbf{w}\\mathbf{x} + \\mathbf{b} = \\\n",
    "\\begin{bmatrix}\n",
    "1.62434536 & -0.61175641 & -0.52817175 & -1.07296862 \\\\\n",
    "0.86540763 & -2.3015387 & 1.74481176 & -0.7612069 \\\\\n",
    "0.3190391 & -0.24937038 & 1.46210794 & -2.06014071\n",
    "\\end{bmatrix} \\\n",
    "\\begin{bmatrix}\n",
    "6.5 \\\\ 2.8 \\\\ 4.6 \\\\ 1.5\n",
    "\\end{bmatrix} + \\\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 0 \\\\ 0\n",
    "\\end{bmatrix} = \\\n",
    "\\begin{bmatrix}\n",
    "4.80628391 \\\\ 6.065165 \\\\ 5.01100252\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "a = g(\\mathbf{z}) = \\sigma(\\mathbf{z}) = \\frac{1}{1 + e^{-\\mathbf{z}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda z: 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlbuISARSuYuIRKD/Bfo3E+QC9laUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10441e908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(-5,5,100), sigmoid(np.linspace(-5,5,100)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188815],\n",
       "       [ 0.99768301],\n",
       "       [ 0.9933799 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat = sigmoid(z)\n",
    "yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "a = g(\\mathbf{z}) = \\sigma(\\mathbf{z}) = \\sigma \\Bigg( \\\n",
    "\\begin{bmatrix}\n",
    "4.80628391 \\\\ 6.065165 \\\\ 5.01100252\n",
    "\\end{bmatrix} \\Bigg) = \\\n",
    "\\begin{bmatrix}\n",
    "0.99188815 \\\\ 0.99768301 \\\\0.9933799\n",
    "\\end{bmatrix} \\neq \\\n",
    "\\begin{bmatrix}\n",
    "0.0 \\\\ 1.0 \\\\ 0.0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathcal{L}(\\mathbf{y}, \\mathbf{\\hat{y}}) = -\\sum_{i=1}^{c} \\mathbf{y}_i\\log{\\mathbf{\\hat{y}}_i} + (1-\\mathbf{y}_i)\\log{(1-\\mathbf{\\hat{y}}_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = lambda y, yHat: -np.sum((y * np.log(yHat) + (1-y) * np.log(1-yHat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1000100500604738e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check 1: should be small for close matches\n",
    "loss(y, np.array([0.00001,0.99999,0.000001]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.841361487913829"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check 2: should be large for poor matches\n",
    "loss(y, np.array([0.99999,0.000001,0.99999]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.8343931585616957"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(y, yHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} \\cdot \\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta z} \\cdot \\frac{\\delta z}{\\delta b} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{a}} = \\\n",
    "- \\frac{\\delta}{\\delta \\mathbf{a}} \\Big[ \\\n",
    "\\mathbf{y}\\log{\\mathbf{a}} + (1-\\mathbf{y})\\log{(1-\\mathbf{a})} \\\n",
    "\\Big]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1-\\mathbf{y}}{1-\\mathbf{\\hat{y}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Derivative of Loss with respect to a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dLda = lambda y, yHat: - (y / yHat) + ((1-y) / (1-yHat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 123.27638239],\n",
       "       [  -1.00232237],\n",
       "       [ 151.05509388]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = dLda(y, yHat)\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numeric_gradient(X, fn, epsilon = 1e-7):\n",
    "    gradients = np.zeros(X.shape)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            plus, minus = [np.copy(X), np.copy(X)]\n",
    "            plus[i,j] += epsilon\n",
    "            minus[i,j] -= epsilon\n",
    "            gradients[i,j] = (fn(plus) - fn(minus)) / (2 * epsilon)\n",
    "            \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 123.27638233],\n",
       "       [  -1.00232238],\n",
       "       [ 151.05509381]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_numeric = numeric_gradient(yHat, lambda yHat: loss(y,yHat))\n",
    "da_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "distance = lambda a, b: np.sqrt(np.sum((a - b) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2303476194109719e-08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(da, da_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Derivative of Loss with respect to z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{z}} \\sigma(\\mathbf{z}) = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{z}} \\Bigg( \\frac{1}{1 + e^{-\\mathbf{z}}} \\Bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\\n",
    "\\Big(\\frac{-1}{1 + e^{-\\mathbf{z}}}\\Big)^{2} \\cdot (e^{-\\mathbf{z}}) \\cdot -1 = \\\n",
    "\\frac{e^{-\\mathbf{z}}}{({1 + e^{-\\mathbf{z}}})^2} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1 - 1 + e^{-\\mathbf{z}}}{(1 + e^{-\\mathbf{z}})(1 + e^{-\\mathbf{z}})}  = \\\n",
    "\\frac{1}{1 + e^{-\\mathbf{z}}} \\cdot \\frac{1 - 1 + e^{-\\mathbf{z}}}{1 + e^{-\\mathbf{z}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\\n",
    "\\frac{1}{1 + e^{-\\mathbf{z}}} \\Big(\\frac{1}{1 + e^{-\\mathbf{z}}} - \\frac{1 + e^{-\\mathbf{z}}}{1 + e^{-\\mathbf{z}}}\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\sigma(\\mathbf{z}) \\big(1-\\sigma(\\mathbf{z})\\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "now for the cool part:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\mathbf{z}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\Big( \\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1-\\mathbf{y}}{1-\\mathbf{\\hat{y}}} \\Big)\\\n",
    "\\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\Big(\\frac{-\\mathbf{y}(1-\\mathbf{\\hat{y}}) + \\mathbf{\\hat{y}}(1-\\mathbf{y})}{\\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})} \\Big)\\\n",
    "\\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= -\\mathbf{y}(1-\\mathbf{\\hat{y}}) + \\mathbf{\\hat{y}}(1-\\mathbf{y}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "= -\\mathbf{y}+\\mathbf{y}\\mathbf{\\hat{y}} + \\mathbf{\\hat{y}}-\\mathbf{\\hat{y}}\\mathbf{y}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\mathbf{\\hat{y}} - \\mathbf{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Awesome news: we don't even need the dLda! can compute both steps in the chain in a single step here. Boom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dLdz = lambda y, yHat: yHat - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188815],\n",
       "       [-0.00231699],\n",
       "       [ 0.9933799 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz = dLdz(y,yHat)\n",
    "dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188821],\n",
       "       [-0.002317  ],\n",
       "       [ 0.99337994]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_numeric = numeric_gradient(z, lambda z: loss(y, sigmoid(z)))\n",
    "dz_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2898331284372404e-08"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dz, dz_numeric) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Derivative of loss with respect to w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{w}} \\mathbf{w}\\mathbf{x} + \\mathbf{b} = \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}} \\cdot \\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}} \\cdot \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (3, 1), (4, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape, da.shape, x.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# need to transpose the x to get the shapes correct\n",
    "dLdw = lambda dz, x: np.dot(dz, x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.44727295e+00,   2.77728681e+00,   4.56268547e+00,\n",
       "          1.48783222e+00],\n",
       "       [ -1.50604601e-02,  -6.48758279e-03,  -1.06581717e-02,\n",
       "         -3.47549078e-03],\n",
       "       [  6.45696934e+00,   2.78146372e+00,   4.56954753e+00,\n",
       "          1.49006985e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw = dLdw(dz, x)\n",
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.44727294e+00,   2.77728668e+00,   4.56268543e+00,\n",
       "          1.48783227e+00],\n",
       "       [ -1.50604507e-02,  -6.48757492e-03,  -1.06581766e-02,\n",
       "         -3.47548657e-03],\n",
       "       [  6.45696936e+00,   2.78146365e+00,   4.56954752e+00,\n",
       "          1.49006977e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_numeric = numeric_gradient(w, lambda w: loss(y, sigmoid(np.dot(w,x) + b)))\n",
    "dw_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.81564089107234e-07"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dw, dw_numeric) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Derivative of Loss with respect to b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "$$\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{b}} \\mathbf{w}\\mathbf{x} + \\mathbf{b} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}} \\cdot \\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dLdb = lambda dz: dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188815],\n",
       "       [-0.00231699],\n",
       "       [ 0.9933799 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = dLdb(dz)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188821],\n",
       "       [-0.002317  ],\n",
       "       [ 0.99337994]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_numeric = numeric_gradient(b, lambda b: loss(y, sigmoid(np.dot(w,x) + b)))\n",
    "db_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2898331284372404e-08"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(db, db_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def forward(x,w,b):\n",
    "    z = np.dot(w,x) + b\n",
    "    a = sigmoid(z)\n",
    "    return z, a\n",
    "\n",
    "def backward(x, y, yhat):\n",
    "    dz = yhat - y\n",
    "    dw = np.dot(dz, x.T)\n",
    "    db = dz\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration 0: 9.834393158561696\n",
      "cost at iteration 100: 0.002145277411514101\n",
      "cost at iteration 200: 0.0018418749490632118\n",
      "cost at iteration 300: 0.0016451870976112407\n",
      "cost at iteration 400: 0.001471482798500676\n",
      "cost at iteration 500: 0.0013176869921403098\n",
      "cost at iteration 600: 0.0011812120786826466\n",
      "cost at iteration 700: 0.00105986590493878\n",
      "cost at iteration 800: 0.0009517801162295505\n",
      "cost at iteration 900: 0.0008553536043709026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "alpha = 0.001\n",
    "_w = np.copy(w)\n",
    "_b = np.copy(b)\n",
    "for i in range(epochs):\n",
    "    z, a = forward(x,_w,_b)\n",
    "    dw, db = backward(x,y,a)\n",
    "    if (i % (epochs / 10) == 0): print(\"cost at iteration {}: {}\".format(i, loss(y,a)))\n",
    "    _w -= alpha * dw\n",
    "    _b -= alpha * da\n",
    "\n",
    "np.round(forward(x,_w,_b)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Batch learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.5,  6.7],\n",
       "       [ 2.8,  2.5],\n",
       "       [ 4.6,  5.8],\n",
       "       [ 1.5,  1.8]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_x[:,:2]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = train_y[:,:2]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00322417, -0.00384054,  0.01133769, -0.01099891],\n",
       "       [-0.00172428, -0.00877858,  0.00042214,  0.00582815],\n",
       "       [-0.01100619,  0.01144724,  0.00901591,  0.00502494]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.randn(Y.shape[0], X.shape[0]) * 0.01\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros((3,1))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{Z} = \\mathbf{WX} + \\mathbf{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00394439,  0.01475727],\n",
       "       [-0.02510381, -0.02056008],\n",
       "       [ 0.00952261,  0.01621377]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.dot(W, X) + b\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A} = \\sigma(\\mathbf{Z}) = \\frac{1}{1+e^{-\\mathbf{Z}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5009861 ,  0.50368925],\n",
       "       [ 0.49372438,  0.49486016],\n",
       "       [ 0.50238063,  0.50405335]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = 1 / (1 + np.exp(-Z))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L} = -\\frac{1}{m} Y\\log{\\hat{Y}} -(1-Y)\\log{(1-\\hat{Y})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOSS = lambda Y, YHat: (-1/Y.shape[1]) * np.sum((Y * np.log(YHat) + (1-Y) * np.log(1-YHat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0836825850107918"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOSS(Y, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00030001500100004195"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOSS(Y, np.array([[0.0001, 0.0001],\n",
    "                  [0.9999, 0.0001],\n",
    "                  [0.0001, 0.9999]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.631021115928768"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOSS(Y, np.array([[0.9999, 0.9999],\n",
    "                  [0.0001, 0.9999],\n",
    "                  [0.9999, 0.0001]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{Z}} = \\frac{1}{m}( \\mathbf{\\hat{Y}} - \\mathbf{Y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25049305,  0.25184463],\n",
       "       [-0.25313781,  0.24743008],\n",
       "       [ 0.25119032, -0.24797332]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ = (A - Y) / (Y.shape[1])\n",
    "dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25049305,  0.25184463],\n",
       "       [-0.25313781,  0.24743008],\n",
       "       [ 0.25119032, -0.24797332]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ_numeric = numeric_gradient(Z, lambda Z: LOSS(Y, 1 / (1 + np.exp(-Z))))\n",
    "dZ_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0500574924496523e-09"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dZ, dZ_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{W}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{Z}} \\cdot \\frac{\\delta \\mathbf{Z}}{\\delta \\mathbf{W}} = \\\n",
    "\\frac{1}{m}(\\mathbf{\\hat{Y}} - \\mathbf{Y})\\mathbf{X}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (3, 2), (4, 2))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape, dZ.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3155638 ,  1.3309921 ,  2.61296685,  0.8290599 ],\n",
       "       [ 0.01238577, -0.09021067,  0.27066054,  0.06566743],\n",
       "       [-0.02868421,  0.08339958, -0.28276982, -0.06956651]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW = np.dot(dZ, X.T)\n",
    "dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3155638 ,  1.3309921 ,  2.61296685,  0.8290599 ],\n",
       "       [ 0.01238577, -0.09021067,  0.27066054,  0.06566743],\n",
       "       [-0.02868421,  0.08339958, -0.28276982, -0.06956651]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW_numeric = numeric_gradient(W, lambda W: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W,X) + b)))))\n",
    "dW_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4509497204145414e-09"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dW, dW_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{Z}} \\cdot \\frac{\\delta \\mathbf{Z}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{1}{m}(\\mathbf{\\hat{Y}} - \\mathbf{Y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25049305,  0.25184463],\n",
       "       [-0.25313781,  0.24743008],\n",
       "       [ 0.25119032, -0.24797332]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = np.array(dZ)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50233767],\n",
       "       [-0.00570773],\n",
       "       [ 0.00321699]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_numeric = numeric_gradient(b, lambda b: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W,X) + b)))))\n",
    "db_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem, wrong shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50233767],\n",
       "       [-0.00570773],\n",
       "       [ 0.00321699]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = np.sum(dZ, axis=1, keepdims=True)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4839322292588777e-09"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(db, db_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration 0: 2.0749979796617715\n",
      "cost at iteration 100000: 0.5448999617856294\n",
      "cost at iteration 200000: 0.5400123291234756\n",
      "cost at iteration 300000: 0.5378009403791113\n",
      "cost at iteration 400000: 0.5365982864689621\n",
      "cost at iteration 500000: 0.5358710480078926\n",
      "cost at iteration 600000: 0.5354007763184792\n",
      "cost at iteration 700000: 0.5350824351478138\n",
      "cost at iteration 800000: 0.5348597183236192\n",
      "cost at iteration 900000: 0.5346999994193413\n",
      "cost at iteration 1000000.0: 0.5345832446202371\n"
     ]
    }
   ],
   "source": [
    "epochs = 1e6\n",
    "step_size = 1e-1\n",
    "_W = np.copy(W)\n",
    "_b = np.copy(b)\n",
    "\n",
    "def descent(X,Y,W,b, epochs, step_size):\n",
    "    for i in range(int(epochs)):\n",
    "        Z = np.dot(W,X) + b\n",
    "        A = 1 / (1+np.exp(-Z))\n",
    "\n",
    "        if (i % (epochs / 10) == 0): print(\"cost at iteration {}: {}\".format(i, LOSS(Y, A)))\n",
    "\n",
    "        dZ = (A - Y) / (Y.shape[1])\n",
    "        dW = np.dot(dZ, X.T)\n",
    "        db = np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        W -= step_size * dW\n",
    "        b -= step_size * db\n",
    "        \n",
    "    print(\"cost at iteration {}: {}\".format(epochs, LOSS(Y, A)))\n",
    "\n",
    "    return W, b\n",
    "\n",
    "_W, _b = descent(train_x,train_y,_W,_b, epochs, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat = 1 / (1+np.exp(-(np.dot(_W,train_x) + _b)))\n",
    "np.round(yHat[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9732142857142857\n",
      "Test Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = np.mean(np.argmax(train_y, axis=0) == np.argmax(yHat, axis=0))\n",
    "\n",
    "yHat_test = 1 / (1+np.exp(-(np.dot(_W,test_x) + _b)))\n",
    "test_accuracy = np.mean(np.argmax(test_y, axis=0) == np.argmax(yHat_test, axis=0))\n",
    "\n",
    "print(\"Training Accuracy: {}\".format(training_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hidden layer with ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{Z}^{[1]} = \\mathbf{W}^{[1]}\\mathbf{X} + \\mathbf{b}^{[1]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L0_nodes = X.shape[0]\n",
    "L1_nodes = 5\n",
    "L2_nodes = Y.shape[0]\n",
    "\n",
    "L0_nodes, L1_nodes, L2_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00900856, -0.00683728, -0.0012289 , -0.00935769],\n",
       "       [-0.00267888,  0.00530355, -0.00691661, -0.00396754],\n",
       "       [-0.00687173, -0.00845206, -0.00671246, -0.00012665],\n",
       "       [-0.0111731 ,  0.00234416,  0.01659802,  0.00742044],\n",
       "       [-0.00191836, -0.00887629, -0.00747158,  0.01692455]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = np.random.randn(L1_nodes, L0_nodes) * 0.01\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = np.zeros((L1_nodes, 1))\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01972176,  0.01929267],\n",
       "       [-0.04033047, -0.0519475 ],\n",
       "       [-0.09939927, -0.10633095],\n",
       "       [ 0.02142003,  0.04062592],\n",
       "       [-0.04630538, -0.0479147 ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1 = np.dot(W1, X) + b1\n",
    "Z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A}^{[1]} = \\text{ReLU}(\\mathbf{Z}^{[1]}) = \\max{(0, \\mathbf{Z}^{[1]})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108298048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(-5,5,100), np.maximum(np.linspace(-5,5,100), 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01972176,  0.01929267],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.02142003,  0.04062592],\n",
       "       [ 0.        ,  0.        ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = np.maximum(Z1, 0)\n",
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{Z}^{[2]} = \\mathbf{W}^{[2]}\\mathbf{A}^{[1]} + \\mathbf{b}^{[2]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00050808, -0.00636996,  0.00190915,  0.02100255,  0.00120159],\n",
       "       [ 0.00617203,  0.0030017 , -0.0035225 , -0.01142518, -0.00349343],\n",
       "       [-0.00208894,  0.00586623,  0.00838983,  0.00931102,  0.00285587]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = np.random.randn(L2_nodes, L1_nodes) * 0.01\n",
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = np.zeros((L2_nodes, 1))\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0004599 ,  0.00086305],\n",
       "       [-0.000123  , -0.00034508],\n",
       "       [ 0.00015824,  0.00033797]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2 = np.dot(W2, A1) + b2\n",
    "Z2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A}^{[2]} = \\sigma(\\mathbf{Z}^{[2]}) = \\frac{1}{1+e^{-\\mathbf{Z}^{[2]}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50011497,  0.50021576],\n",
       "       [ 0.49996925,  0.49991373],\n",
       "       [ 0.50003956,  0.50008449]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = 1 / (1 + np.exp(-Z2))\n",
    "A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L} = -\\frac{1}{m} Y\\log{\\hat{Y}} -(1-Y)\\log{(1-\\hat{Y})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0796719044469447"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOSS(Y, A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{W}^{[2]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{Z}^{[2]}} \\cdot \\frac{\\delta \\mathbf{Z}^{[2]}}{\\delta \\mathbf{W}^{[2]}} = \\\n",
    "\\frac{1}{m}(\\mathbf{A}^{[2]} - \\mathbf{Y})\\mathbf{A}^{[1]^T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25005749,  0.25010788],\n",
       "       [-0.25001538,  0.24995686],\n",
       "       [ 0.25001978, -0.24995775]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ2 = (1 / Y.shape[1]) * (A2 - Y)\n",
    "dZ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00975682,  0.        ,  0.        ,  0.0155171 ,  0.        ],\n",
       "       [-0.00010841,  0.        ,  0.        ,  0.00479939,  0.        ],\n",
       "       [ 0.00010848,  0.        ,  0.        , -0.00479933,  0.        ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(dZ2, A1.T)\n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00975682,  0.        ,  0.        ,  0.0155171 ,  0.        ],\n",
       "       [-0.00010841,  0.        ,  0.        ,  0.00479939,  0.        ],\n",
       "       [ 0.00010848,  0.        ,  0.        , -0.00479933,  0.        ]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2_numeric = numeric_gradient(W2, lambda W: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W,A1) + b2)))))\n",
    "dW2_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9071113101281613e-09"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dW2, dW2_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{b}^{[2]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{Z}^{[2]}} \\cdot \\frac{\\delta \\mathbf{Z}^{[2]}}{\\delta \\mathbf{b}^{[2]}} = \\\n",
    "\\frac{1}{m}(\\mathbf{A}^{[2]} - \\mathbf{Y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.00165368e-01],\n",
       "       [ -5.85109954e-05],\n",
       "       [  6.20265278e-05]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.00165369e-01],\n",
       "       [ -5.85109738e-05],\n",
       "       [  6.20259399e-05]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2_numeric = numeric_gradient(b2, lambda b2: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W2,A1) + b2)))))\n",
    "db2_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0995861353294133e-09"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(db2, db2_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{A}^{[1]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{Z}^{[2]}} \\cdot \\frac{\\delta \\mathbf{Z}^{[2]}}{\\delta \\mathbf{A}^{[1]}} = \\\n",
    "\\mathbf{W}^{[2]^T}\\frac{1}{m}(\\mathbf{A}^{[2]} - \\mathbf{Y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2), (3, 2), (3, 5))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1.shape, dZ2.shape, W2.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.93833098e-03,   2.19196307e-03],\n",
       "       [ -8.76653243e-04,  -2.30919015e-03],\n",
       "       [  3.45570173e-03,  -2.50008210e-03],\n",
       "       [  1.04362558e-02,   6.97391078e-05],\n",
       "       [  1.88790178e-03,  -1.28652677e-03]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA1 = np.dot(W2.T, dZ2)\n",
    "dA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.93833172e-03,   2.19196439e-03],\n",
       "       [ -8.76649864e-04,  -2.30919062e-03],\n",
       "       [  3.45570239e-03,  -2.50008236e-03],\n",
       "       [  1.04362541e-02,   6.97397695e-05],\n",
       "       [  1.88790095e-03,  -1.28652644e-03]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA1_numeric = numeric_gradient(A1, lambda A1: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W2,A1) + b2)))))\n",
    "dA1_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2960959561362194e-09"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dA1, dA1_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{Z}^{[1]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{A}^{[1]}} \\cdot \\frac{\\delta \\mathbf{A}^{[1]}}{\\delta \\mathbf{Z}^{[1]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{A}^{[1]}} \\cdot \\frac{\\delta}{\\delta \\mathbf{Z}^{[1]}} \\\n",
    "\\Big[ \\max{(0, \\mathbf{Z}^{[1]})} \\Big]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta}{\\delta \\mathbf{Z}^{[1]}} \\\n",
    "\\Big[ \\max{(0, \\mathbf{Z}^{[1]})} \\Big] = \\\n",
    "\\begin{cases}\n",
    "0 &\\quad\\text{if } \\mathbf{Z^{[1]}} < 0 \\\\ \n",
    "1 &\\quad\\text{if } \\mathbf{Z^{[1]}} >= 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.93833098e-03,   2.19196307e-03],\n",
       "       [ -0.00000000e+00,  -0.00000000e+00],\n",
       "       [  0.00000000e+00,  -0.00000000e+00],\n",
       "       [  1.04362558e-02,   6.97391078e-05],\n",
       "       [  0.00000000e+00,  -0.00000000e+00]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ1 = dA1 * np.array(Z1 >= 0, dtype=float)\n",
    "dZ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.93833172e-03,   2.19196439e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.04362541e-02,   6.97397695e-05],\n",
       "       [  0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ1_numeric = numeric_gradient(Z1, lambda Z1: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W2,np.maximum(Z1, 0)) + b2)))))\n",
    "dZ1_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3470716908607333e-09"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dZ1, dZ1_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{W}^{[1]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{Z}^{[1]}} \\cdot \\frac{\\delta \\mathbf{Z}^{[1]}}{\\delta \\mathbf{W}^{[1]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{Z}^{[1]}} \\cdot \\mathbf{X}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 4), (5, 2), (4, 2))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape, dZ1.shape, X.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.08700121e-03,   5.25809360e-05,   3.79706331e-03,\n",
       "          1.03803706e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  6.83029144e-02,   2.93958639e-02,   4.84112633e-02,\n",
       "          1.57799140e-02],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW1 = np.dot(dZ1,X.T)\n",
    "dW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.08700168e-03,   5.25801624e-05,   3.79706266e-03,\n",
       "          1.03803854e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  6.83029144e-02,   2.93958635e-02,   4.84112639e-02,\n",
       "          1.57799129e-02],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW1_numeric = numeric_gradient(W1, lambda W1: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W2,np.maximum((np.dot(W1,X) + b1), 0)) + b2)))))\n",
    "dW1_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2616587607253184e-09"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dW1, dW1_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{b}^{[1]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{Z}^{[1]}} \\cdot \\frac{\\delta \\mathbf{Z}^{[1]}}{\\delta \\mathbf{b}^{[1]}} = \\\n",
    "\\frac{\\delta L}{\\delta \\mathbf{Z}^{[1]}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00025363],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.01050599],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
    "db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00025363],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.010506  ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db1_numeric = numeric_gradient(b1, lambda b1: LOSS(Y, 1 / (1 + np.exp(-(np.dot(W2,np.maximum((np.dot(W1,X) + b1), 0)) + b2)))))\n",
    "db1_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.338965817850446e-09"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(db1, db1_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration 0: 2.0795796401879154\n",
      "cost at iteration 100000: 0.09898576767593914\n",
      "cost at iteration 200000: 0.09829451852201666\n",
      "cost at iteration 300000: 0.09825865334561558\n",
      "cost at iteration 400000: 0.0982397567699389\n",
      "cost at iteration 500000: 0.09822791187010155\n",
      "cost at iteration 600000: 0.09821984111738503\n",
      "cost at iteration 700000: 0.09821404043461865\n",
      "cost at iteration 800000: 0.09820961442362983\n",
      "cost at iteration 900000: 0.0982061743885833\n",
      "cost at iteration 1000000.0: 0.09820343030826469\n"
     ]
    }
   ],
   "source": [
    "epochs = 1e6\n",
    "step_size = 1e-1\n",
    "\n",
    "_W1 = np.copy(W1)\n",
    "_b1 = np.copy(b1)\n",
    "\n",
    "_W2 = np.copy(W2)\n",
    "_b2 = np.copy(b2)\n",
    "\n",
    "\n",
    "def two_layer_descent(X,Y,W2,b2,W1,b1, epochs, step_size):\n",
    "    for i in range(int(epochs)):\n",
    "        Z1 = np.dot(W1,X) + b1\n",
    "        A1 = np.maximum(0, Z1)\n",
    "\n",
    "        Z2 = np.dot(W2,A1) + b2\n",
    "        A2 = 1 / (1 + np.exp(-Z2))\n",
    "        \n",
    "        if (i % (epochs / 10) == 0): print(\"cost at iteration {}: {}\".format(i, LOSS(Y, A2)))\n",
    "\n",
    "        dZ2 = (A2 - Y) / Y.shape[1]\n",
    "        dW2 = np.dot(dZ2, A1.T)\n",
    "        db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dA1 = np.dot(W2.T, dZ2)\n",
    "        dZ1 = dA1 * np.array(Z1 >= 0, dtype=float)\n",
    "        dW1 = np.dot(dZ1,X.T)\n",
    "        db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        W2 -= step_size * dW2\n",
    "        b2 -= step_size * db2\n",
    "        W1 -= step_size * dW1\n",
    "        b1 -= step_size * db1\n",
    "        \n",
    "    print(\"cost at iteration {}: {}\".format(epochs, LOSS(Y, A2)))\n",
    "\n",
    "    return W2, b2, W1, b1\n",
    "\n",
    "_W2, _b2, _W1, _b1 = two_layer_descent(train_x,train_y,_W2,_b2,_W1,_b1, epochs, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9821428571428571\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "forward = lambda X, W1, b1, W2, b2: 1 / (1 + np.exp(-(np.dot(W2,np.maximum((np.dot(W1,X) + b1), 0)) + b2)))\n",
    "\n",
    "train_prediction = forward(train_x, _W1, _b1, _W2, _b2)\n",
    "test_prediction = forward(test_x, _W1, _b1, _W2, _b2)\n",
    "\n",
    "training_accuracy = np.mean(np.argmax(train_y, axis=0) == np.argmax(train_prediction, axis=0))\n",
    "test_accuracy = np.mean(np.argmax(test_y, axis=0) == np.argmax(test_prediction, axis=0))\n",
    "\n",
    "print(\"Training Accuracy: {}\".format(training_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(train_prediction[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_prediction[:,:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
