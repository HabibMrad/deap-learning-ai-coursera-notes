{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic Regression for Classification of Digits\n",
    "\n",
    "I get pretty good results on 0 vs 1, implying that telling the difference between a \"0\" and a \"1\" is not a hard problem anymore. Also pretty epic results on predicting 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "digits = load_digits(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHsAAACYCAYAAAB0zuXRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wXyunCfSqe1wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108604ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=9, figsize=(20,10))\n",
    "plt.gray()\n",
    "\n",
    "for i in range(9):\n",
    "    axes[i].imshow(digits.images[i])\n",
    "    axes[i].set_title(digits.target[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 270), (1, 270), (64, 90), (1, 90))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(digits.images, digits.target)\n",
    "\n",
    "train_x, test_x = [x.reshape(x.shape[0], -1).T / 16 for x in [train_x, test_x]]\n",
    "train_y, test_y = [y.reshape(1, y.shape[0]) for y in [train_y, test_y]]\n",
    "\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, step_size, epochs):\n",
    "    w, b = np.random.randn(X.shape[0], 1), 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        yhat = 1 / (1 + np.exp( - (np.dot(w.T, X) + b)))\n",
    "\n",
    "        if (i % (epochs/10) == 0):  print(\"Cost at iteration {}: {}\".format(i, -np.mean(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))))\n",
    "\n",
    "        w = w - step_size * (1 / w.shape[0]) * np.dot(X, (yhat - y).T) \n",
    "        b = b - step_size * np.mean(yhat - y)\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0: 2.4401216178570317\n",
      "Cost at iteration 10000: 0.03170841319095779\n",
      "Cost at iteration 20000: 0.01737477651304169\n",
      "Cost at iteration 30000: 0.012198706251352399\n",
      "Cost at iteration 40000: 0.009466403471614078\n",
      "Cost at iteration 50000: 0.007762538809502362\n",
      "Cost at iteration 60000: 0.006593219276485362\n",
      "Cost at iteration 70000: 0.005738768014801082\n",
      "Cost at iteration 80000: 0.005085977976521272\n",
      "Cost at iteration 90000: 0.0045703673795715865\n",
      "Accuracy on train set: 100.0%\n",
      "Accuracy on test set: 100.0%\n"
     ]
    }
   ],
   "source": [
    "w, b = gradient_descent(train_x, train_y, 0.001, 100000)\n",
    "        \n",
    "predict = lambda X, w, b: np.array((1 / (1 + np.exp(-1 * (np.dot(w.T, X) + b)))) > 0.5, dtype=int)\n",
    "accuracy = lambda y, yhat: np.mean(y == yhat) * 100\n",
    "\n",
    "print(\"Accuracy on train set: {}%\".format(accuracy(train_y, predict(train_x,w,b))))\n",
    "print(\"Accuracy on test set: {}%\".format(accuracy(test_y, predict(test_x,w,b))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try predicting more than binary and try predict 0 through 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHsAAACNCAYAAAAn1Xb5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASIRhDwAAAAAAQCL/C1pwULTF6jQvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1083dfe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits10 = load_digits(10)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(20,10))\n",
    "plt.gray()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(digits10.images[i])\n",
    "    axes[i].set_title(digits10.target[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to wrangle the data to vectors\n",
    "scale = digits10.images.max()\n",
    "\n",
    "# a matrix with each row representing the image, and \"normalized\" by dividing through max\n",
    "X = digits10.images.reshape(digits10.images.shape[0], -1) / scale\n",
    "\n",
    "# one hot encode the output\n",
    "y = np.zeros((len(digits10.target), 10))\n",
    "y[np.arange(len(digits10.target)), digits10.target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1347) (10, 1347)\n",
      "(64, 450) (10, 450)\n"
     ]
    }
   ],
   "source": [
    "# for convenience, change X and y to be a matrix where each *column* represents the training input/output\n",
    "train_x, test_x, train_y, test_y = (np.array(set.T) for set in train_test_split(X, y))\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 64 1347\n"
     ]
    }
   ],
   "source": [
    "def dimensions(X,y): \n",
    "    '''\n",
    "    c = the number of classifications possible for each given ouput\n",
    "    D = the number of features\n",
    "    m = number of training samples\n",
    "    '''\n",
    "    c = y.shape[0]\n",
    "    D, m = X.shape\n",
    "    return c, D, m\n",
    "\n",
    "c, D, m = dimensions(train_x, train_y)\n",
    "print(c,D,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{z} = \\mathbf{w}^T\\mathbf{X} + \\mathbf{b}$\n",
    "\n",
    "$ \\mathbf{z} = \n",
    "\\\n",
    "\\begin{bmatrix} \\\n",
    "z_1^{(1)} & z_1^{(2)} & \\cdots & z_1^{(m)} \\\\\n",
    "z_2^{(1)} & z_2^{(2)} & \\cdots & z_2^{(m)} \\\\\n",
    "\\vdots & \\vdots &  \\ddots &  \\\\\n",
    "z_c^{(1)} & z_c^{(2)} &   & z_c^{(m)} \\\\\n",
    "\\end{bmatrix} \\\n",
    "= \\\n",
    "\\begin{bmatrix} \\\n",
    "w_{1,1} & w_{1,2} & \\cdots & w_{1,D} \\\\\n",
    "w_{2,1} & w_{2,2} & \\cdots & w_{2,D} \\\\\n",
    "\\vdots & \\vdots & \\ddots &  \\\\\n",
    "w_{c,1} & w_{c,2} &  & w_{c,D} \\\\\n",
    "\\end{bmatrix} \\\n",
    "\\\n",
    "\\begin{bmatrix} \\\n",
    "x_1^{(1)} & x_1^{(2)} & \\cdots & x_1^{(m)} \\\\\n",
    "x_2^{(1)} & x_2^{(2)} & \\cdots & x_2^{(m)} \\\\\n",
    "\\vdots & \\vdots &  \\ddots &  \\\\\n",
    "x_D^{(1)} & x_D^{(2)} &   & x_D^{(m)} \\\\\n",
    "\\end{bmatrix}\n",
    " + \\\n",
    "\\begin{bmatrix} \\\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "\\vdots\\\\\n",
    "b_c \\\\\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\mathbf{\\hat{y}} = ({1 + e^{-\\mathbf{z}}})^{-1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize our weights and biases to zero\n",
    "w = np.zeros((D,c))\n",
    "b = np.zeros((c,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = lambda w,X,b: np.dot(w.T, X) + b\n",
    "yHat = lambda z: 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\mathcal{L}( \\mathbf{y}^{(i)}, \\mathbf{\\hat{y}}^{(i)}) = -(\\\n",
    "\\mathbf{y}^{(i)} \\cdot \\ln{\\mathbf{\\hat{y}}^{(i)}} + \\\n",
    "(1 - \\mathbf{y}^{(i)}) \\cdot \\ln{(1 - \\mathbf{\\hat{y}}^{(i)})})\n",
    "$\n",
    "\n",
    "$\n",
    "\\mathbf{J} = -\\frac{1}{m} \\sum_i^m \\mathcal{L}( \\mathbf{y}^{(i)}, \\mathbf{\\hat{y}}^{(i)})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J = lambda y, yHat: -np.mean(y * np.log(yHat) + (1 - y) * np.log(1 - yHat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{\\hat{y}}} = \\\n",
    "\\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1 - \\mathbf{y}}{1 - \\mathbf{\\hat{y}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} = \\mathbf{\\hat{y}}(1 - \\mathbf{\\hat{y}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\delta \\mathbf{\\hat{z}}}{\\delta \\mathbf{w}} = \\mathbf{X} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathbf{J}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} = \\\n",
    "\\Big[\\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1 - \\mathbf{y}}{1 - \\mathbf{\\hat{y}}}\\Big] \\dot \\\n",
    "\\mathbf{\\hat{y}}(1 - \\mathbf{\\hat{y}}) \\cdot \\mathbf{X} = \\\n",
    "(\\mathbf{\\hat{y}} - \\mathbf{y}) \\cdot \\mathbf{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dJdw = lambda X, y, yHat: np.dot(X, (yHat - y).T) / len(X)\n",
    "dJdb = lambda y, yHat: np.mean(yHat - y, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = yHat(z(w,train_x,b))\n",
    "assert(a.shape == train_y.shape)\n",
    "\n",
    "dw = dJdw(train_x, train_y, a)\n",
    "assert(dw.shape == w.shape)\n",
    "\n",
    "db = dJdb(train_y, a)\n",
    "assert(db.shape == b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "alpha = 0.001\n",
    "\n",
    "def descend(X, y, w, b):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        a = yHat(z(w,X,b))\n",
    "        \n",
    "        if (i % (epochs / 10) == 0): print(\"cost at iteration {}: {}\".format(i,J(y, a)))\n",
    "            \n",
    "        w = w - alpha * dJdw(X, y, a)\n",
    "        b = b - alpha * dJdb(y, a)\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration 0: 0.6931471805599453\n",
      "cost at iteration 10000: 0.057414095020112216\n",
      "cost at iteration 20000: 0.04545212183435679\n",
      "cost at iteration 30000: 0.040094949749305775\n",
      "cost at iteration 40000: 0.03681075560552498\n",
      "cost at iteration 50000: 0.03450554954129363\n",
      "cost at iteration 60000: 0.032761605794235024\n",
      "cost at iteration 70000: 0.03137796066989168\n",
      "cost at iteration 80000: 0.030242994119979986\n",
      "cost at iteration 90000: 0.029288487996844744\n"
     ]
    }
   ],
   "source": [
    "c, D, m = dimensions(train_x, train_y)\n",
    "\n",
    "w = np.zeros((D,c))\n",
    "b = np.zeros((c,1))\n",
    "\n",
    "w, b = descend(train_x, train_y, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 98.21826280623608 %\n",
      "Accuracy on test set: 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "accuracy = lambda y, yhat: np.mean(y.argmax(axis=0) == yhat.argmax(axis=0)) * 100\n",
    "\n",
    "print(\"Accuracy on train set: {} %\".format(accuracy(train_y, yHat(z(w,train_x,b)))))\n",
    "print(\"Accuracy on test set: {}%\".format(accuracy(test_y, yHat(z(w,test_x,b)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 True\n",
      "7 7 True\n",
      "0 0 True\n",
      "0 0 True\n",
      "9 9 True\n",
      "4 4 True\n",
      "3 3 True\n",
      "9 9 True\n",
      "5 5 True\n",
      "6 6 True\n",
      "3 3 True\n",
      "2 2 True\n",
      "1 1 True\n",
      "7 7 True\n",
      "4 4 True\n",
      "6 6 True\n",
      "2 2 True\n",
      "7 7 True\n",
      "9 9 True\n",
      "4 4 True\n"
     ]
    }
   ],
   "source": [
    "for sample in range(20):\n",
    "    actual = test_y.argmax(axis=0)[sample]\n",
    "    prediction = yHat(z(w,test_x,b)).argmax(axis=0)[sample] \n",
    "    print(actual, prediction, actual == prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
