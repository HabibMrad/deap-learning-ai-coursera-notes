{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150, 3))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset['data']\n",
    "\n",
    "Y = np.zeros((len(dataset['target']), 3))\n",
    "Y[np.arange(len(dataset['target'])), dataset['target']] = 1\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 112), (4, 38), (3, 112), (3, 38)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = [np.array(M.T) for M in train_test_split(X, Y, random_state=1)]\n",
    "[m.shape for m in (train_x, test_x, train_y, test_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow neural network, with one hidden layer and an output layer, using relu activation function for hidden layer and sigmoid activation for output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{z} = \\mathbf{w}\\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{a} = \\frac{1}{1 + e^{-\\mathbf{z}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.5],\n",
       "       [ 2.8],\n",
       "       [ 4.6],\n",
       "       [ 1.5]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_x[:,:1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_y[:,:1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641, -0.52817175, -1.07296862],\n",
       "       [ 0.86540763, -2.3015387 ,  1.74481176, -0.7612069 ],\n",
       "       [ 0.3190391 , -0.24937038,  1.46210794, -2.06014071]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "w = np.random.randn(y.shape[0], x.shape[0])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros((y.shape[0], 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.80628391],\n",
       "       [ 6.065165  ],\n",
       "       [ 5.01100252]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.dot(w,x) + b\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{z} = \\\n",
    "\\mathbf{w}\\mathbf{x} + \\mathbf{b} = \\\n",
    "\\begin{bmatrix}\n",
    "1.62434536 & -0.61175641 & -0.52817175 & -1.07296862 \\\\\n",
    "0.86540763 & -2.3015387 & 1.74481176 & -0.7612069 \\\\\n",
    "0.3190391 & -0.24937038 & 1.46210794 & -2.06014071\n",
    "\\end{bmatrix} \\\n",
    "\\begin{bmatrix}\n",
    "6.5 \\\\ 2.8 \\\\ 4.6 \\\\ 1.5\n",
    "\\end{bmatrix} + \\\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 0 \\\\ 0\n",
    "\\end{bmatrix} = \\\n",
    "\\begin{bmatrix}\n",
    "4.80628391 \\\\ 6.065165 \\\\ 5.01100252\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a = g(\\mathbf{z}) = \\sigma(\\mathbf{z}) = \\frac{1}{1 + e^{-\\mathbf{z}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda z: 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlbuISARSuYuIRKD/Bfo3E+QC9laUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107fc1518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(-5,5,100), sigmoid(np.linspace(-5,5,100)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188815],\n",
       "       [ 0.99768301],\n",
       "       [ 0.9933799 ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat = sigmoid(z)\n",
    "yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a = g(\\mathbf{z}) = \\sigma(\\mathbf{z}) = \\sigma \\Bigg( \\\n",
    "\\begin{bmatrix}\n",
    "4.80628391 \\\\ 6.065165 \\\\ 5.01100252\n",
    "\\end{bmatrix} \\Bigg) = \\\n",
    "\\begin{bmatrix}\n",
    "0.99188815 \\\\ 0.99768301 \\\\0.9933799\n",
    "\\end{bmatrix} \\neq \\\n",
    "\\begin{bmatrix}\n",
    "0.0 \\\\ 1.0 \\\\ 0.0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}(\\mathbf{y}, \\mathbf{\\hat{y}}) = -\\sum_{i=1}^{c} \\mathbf{y}_i\\log{\\mathbf{\\hat{y}}_i} + (1-\\mathbf{y}_i)\\log{(1-\\mathbf{\\hat{y}}_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lambda y, yHat: -np.sum((y * np.log(yHat) + (1-y) * np.log(1-yHat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1000100500604738e-05"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check 1: should be small for close matches\n",
    "loss(y, np.array([0.00001,0.99999,0.000001]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.841361487913829"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check 2: should be large for poor matches\n",
    "loss(y, np.array([0.99999,0.000001,0.99999]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.8343931585616957"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(y, yHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} \\cdot \\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta z} \\cdot \\frac{\\delta z}{\\delta b} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{a}} = \\\n",
    "- \\frac{\\delta}{\\delta \\mathbf{a}} \\Big[ \\\n",
    "\\mathbf{y}\\log{\\mathbf{a}} + (1-\\mathbf{y})\\log{(1-\\mathbf{a})} \\\n",
    "\\Big]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1-\\mathbf{y}}{1-\\mathbf{\\hat{y}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Loss with respect to a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dLda = lambda y, yHat: - (y / yHat) + ((1-y) / (1-yHat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 123.27638239],\n",
       "       [  -1.00232237],\n",
       "       [ 151.05509388]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = dLda(y, yHat)\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dLda_numeric(y, yHat):\n",
    "    numeric = np.zeros(yHat.shape)\n",
    "    epsilon = 1e-7\n",
    "    for i, row in enumerate(yHat):\n",
    "        for j, c in enumerate(row):\n",
    "            plus = np.copy(yHat)\n",
    "            minus = np.copy(yHat)\n",
    "            plus[i,j] += epsilon\n",
    "            minus[i,j] -= epsilon\n",
    "            numeric[i,j] = (loss(y, plus) - loss(y, minus)) / (2 * epsilon)\n",
    "    return numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 123.27638233],\n",
       "       [  -1.00232238],\n",
       "       [ 151.05509381]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_numeric = dLda_numeric(y,yHat)\n",
    "da_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance = lambda a, b: np.sqrt(np.sum((a - b) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2303476194109719e-08"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(da, da_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Loss with respect to z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}} = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{z}} \\sigma(\\mathbf{z}) = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{z}} \\Bigg( \\frac{1}{1 + e^{-\\mathbf{z}}} \\Bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\\n",
    "\\Big(\\frac{-1}{1 + e^{-\\mathbf{z}}}\\Big)^{2} \\cdot (e^{-\\mathbf{z}}) \\cdot -1 = \\\n",
    "\\frac{e^{-\\mathbf{z}}}{({1 + e^{-\\mathbf{z}}})^2} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\frac{1 - 1 + e^{-\\mathbf{z}}}{(1 + e^{-\\mathbf{z}})(1 + e^{-\\mathbf{z}})}  = \\\n",
    "\\frac{1}{1 + e^{-\\mathbf{z}}} \\cdot \\frac{1 - 1 + e^{-\\mathbf{z}}}{1 + e^{-\\mathbf{z}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\\n",
    "\\frac{1}{1 + e^{-\\mathbf{z}}} \\Big(\\frac{1}{1 + e^{-\\mathbf{z}}} - \\frac{1 + e^{-\\mathbf{z}}}{1 + e^{-\\mathbf{z}}}\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\sigma(\\mathbf{z}) \\big(1-\\sigma(\\mathbf{z})\\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now for the cool part:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\mathbf{z}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{\\hat{y}}} \\cdot \\\n",
    "\\frac{\\delta \\mathbf{\\hat{y}}}{\\delta \\mathbf{z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\Big( \\frac{-\\mathbf{y}}{\\mathbf{\\hat{y}}} + \\frac{1-\\mathbf{y}}{1-\\mathbf{\\hat{y}}} \\Big)\\\n",
    "\\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\Big(\\frac{-\\mathbf{y}(1-\\mathbf{\\hat{y}}) + \\mathbf{\\hat{y}}(1-\\mathbf{y})}{\\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})} \\Big)\\\n",
    "\\mathbf{\\hat{y}}(1-\\mathbf{\\hat{y}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= -\\mathbf{y}(1-\\mathbf{\\hat{y}}) + \\mathbf{\\hat{y}}(1-\\mathbf{y}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= -\\mathbf{y}+\\mathbf{y}\\mathbf{\\hat{y}} + \\mathbf{\\hat{y}}-\\mathbf{\\hat{y}}\\mathbf{y}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\mathbf{\\hat{y}} - \\mathbf{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome news: we don't even need the dLda! can compute both steps in the chain in a single step here. Boom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dLdz = lambda y, yHat: yHat - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188815],\n",
       "       [-0.00231699],\n",
       "       [ 0.9933799 ]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz = dLdz(y,yHat)\n",
    "dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dLdz_numeric(z, y, epsilon = 1e-7):\n",
    "    numeric = np.zeros(z.shape)\n",
    "    for i, row in enumerate(z):\n",
    "        for j, c in enumerate(row):\n",
    "            plus, minus = [np.copy(z), np.copy(z)]\n",
    "            plus[i,j] += epsilon\n",
    "            minus[i,j] -= epsilon\n",
    "            numeric[i,j] = (loss(y, sigmoid(plus)) - loss(y, sigmoid(minus))) / (2 * epsilon)\n",
    "    return numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188821],\n",
       "       [-0.002317  ],\n",
       "       [ 0.99337994]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_numeric = dLdz_numeric(z,y)\n",
    "dz_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2898331284372404e-08"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dz, dz_numeric) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of loss with respect to w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{w}} \\mathbf{w}\\mathbf{x} + \\mathbf{b} = \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}} \\cdot \\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{w}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}} \\cdot \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (3, 1), (4, 1))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape, da.shape, x.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to transpose the x to get the shapes correct\n",
    "dLdw = lambda dz, x: np.dot(dz, x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.44727295e+00,   2.77728681e+00,   4.56268547e+00,\n",
       "          1.48783222e+00],\n",
       "       [ -1.50604601e-02,  -6.48758279e-03,  -1.06581717e-02,\n",
       "         -3.47549078e-03],\n",
       "       [  6.45696934e+00,   2.78146372e+00,   4.56954753e+00,\n",
       "          1.49006985e+00]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw = dLdw(dz, x)\n",
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dLdw_numeric(w,b,x,y, epsilon = 1e-7):\n",
    "    numeric = np.zeros(w.shape)\n",
    "    for i in range(w.shape[0]):\n",
    "        for j in range(w.shape[1]):\n",
    "            plus, minus = [np.copy(w), np.copy(w)]\n",
    "            plus[i,j] += epsilon\n",
    "            minus[i,j] -= epsilon\n",
    "            numeric[i,j] = (loss(y, sigmoid(np.dot(plus,x) + b)) - loss(y, sigmoid(np.dot(minus,x) + b))) / (2 * epsilon)\n",
    "    return numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.44727294e+00,   2.77728668e+00,   4.56268543e+00,\n",
       "          1.48783227e+00],\n",
       "       [ -1.50604507e-02,  -6.48757492e-03,  -1.06581766e-02,\n",
       "         -3.47548657e-03],\n",
       "       [  6.45696936e+00,   2.78146365e+00,   4.56954752e+00,\n",
       "          1.49006977e+00]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_numeric = dLdw_numeric(w,b,x,y)\n",
    "dw_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.81564089107234e-07"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(dw, dw_numeric) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Loss with respect to b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta}{\\delta \\mathbf{b}} \\mathbf{w}\\mathbf{x} + \\mathbf{b} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}} \\cdot \\frac{\\delta \\mathbf{z}}{\\delta \\mathbf{b}} = \\\n",
    "\\frac{\\delta \\mathcal{L}}{\\delta \\mathbf{z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dLdb = lambda dz: dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188815],\n",
       "       [-0.00231699],\n",
       "       [ 0.9933799 ]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = dLdb(dz)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dLdb_numeric(w,b,x,y, epsilon = 1e-7):\n",
    "    numeric = np.zeros(b.shape)\n",
    "    for i in range(b.shape[0]):\n",
    "        for j in range(b.shape[1]):\n",
    "            plus, minus = [np.copy(b), np.copy(b)]\n",
    "            plus[i,j] += epsilon\n",
    "            minus[i,j] -= epsilon\n",
    "            numeric[i,j] = (loss(y, sigmoid(np.dot(w,x) + plus)) - loss(y, sigmoid(np.dot(w,x) + minus))) / (2 * epsilon)\n",
    "    return numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99188821],\n",
       "       [-0.002317  ],\n",
       "       [ 0.99337994]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_numeric = dLdb_numeric(w,b,x,y)\n",
    "db_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2898331284372404e-08"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(db, db_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(x,w,b):\n",
    "    z = np.dot(w,x) + b\n",
    "    a = sigmoid(z)\n",
    "    return z, a\n",
    "\n",
    "def backward(x, y, yhat):\n",
    "    dz = yhat - y\n",
    "    dw = np.dot(dz, x.T)\n",
    "    db = dz\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration 0: 9.834393158561696\n",
      "cost at iteration 100: 0.002145277411514101\n",
      "cost at iteration 200: 0.0018418749490632118\n",
      "cost at iteration 300: 0.0016451870976112407\n",
      "cost at iteration 400: 0.001471482798500676\n",
      "cost at iteration 500: 0.0013176869921403098\n",
      "cost at iteration 600: 0.0011812120786826466\n",
      "cost at iteration 700: 0.00105986590493878\n",
      "cost at iteration 800: 0.0009517801162295505\n",
      "cost at iteration 900: 0.0008553536043709026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "alpha = 0.001\n",
    "_w = np.copy(w)\n",
    "_b = np.copy(b)\n",
    "for i in range(epochs):\n",
    "    z, a = forward(x,_w,_b)\n",
    "    dw, db = backward(x,y,a)\n",
    "    if (i % (epochs / 10) == 0): print(\"cost at iteration {}: {}\".format(i, loss(y,a)))\n",
    "    _w -= alpha * dw\n",
    "    _b -= alpha * da\n",
    "\n",
    "np.round(forward(x,_w,_b)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden layer with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
